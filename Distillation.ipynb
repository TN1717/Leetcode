{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e5935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/sunhao11/guorui/HZQ/quantizaton/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/sunhao11/guorui/HZQ/quantizaton/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/sunhao11/guorui/HZQ/quantizaton/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/root/sunhao11/guorui/HZQ/quantizaton/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/root/sunhao11/guorui/HZQ/quantizaton/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "2025-04-24 18:15:03,925 - INFO - Current script path: /root/sunhao11/guorui/HZQ/Distillation.ipynb\n",
      "2025-04-24 18:15:03,926 - INFO - Current script directory: /root/sunhao11/guorui/HZQ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from textbrewer import GeneralDistiller, TrainingConfig, DistillationConfig\n",
    "from datasets import load_dataset\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# 配置日志，设置日志级别为INFO，指定日志格式\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# 获取当前脚本文件的绝对路径\n",
    "current_script_path = os.path.abspath('Distillation.ipynb')\n",
    "logger.info(f\"Current script path: {current_script_path}\")\n",
    "\n",
    "# 获取当前脚本文件所在的目录\n",
    "current_script_dir = os.path.dirname(current_script_path)\n",
    "logger.info(f\"Current script directory: {current_script_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2087b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义方法\n",
    "\n",
    "def messages_to_prompt(messages, system_prompt='You are a helpful assistant.', fill_system_prompt=True):\n",
    "    \"\"\"\n",
    "    将 messages 转换为 Qwen2 模型的输入 prompt。\n",
    "    \n",
    "    :param messages: 包含对话消息的列表，每个消息是一个字典，包含 'role' 和 'content' 字段。\n",
    "                    例如: [{'role': 'system', 'content': 'You are a helpful assistant.'}, \n",
    "                          {'role': 'user', 'content': 'What is the capital of France?'}]\n",
    "    :return: 转换后的 prompt 字符串，适用于 Qwen2 模型。\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "    if fill_system_prompt and messages[0]['role'] != 'system':\n",
    "        messages.insert(0, {'role': 'system', 'content': system_prompt})\n",
    "    for message in messages:\n",
    "        role = message['role']\n",
    "        content = message['content']\n",
    "        if role == 'system':\n",
    "            prompt += f\"<|im_start|>system\\n{content}<|im_end|>\\n\"\n",
    "        elif role == 'user':\n",
    "            prompt += f\"<|im_start|>user\\n{content}<|im_end|>\\n\"\n",
    "        elif role == 'assistant':\n",
    "            prompt += f\"<|im_start|>assistant\\n{content}<|im_end|>\\n\"\n",
    "        elif role == 'shipper':\n",
    "            prompt += f\"<|im_start|>shipper\\n{content}<|im_end|>\\n\"\n",
    "        elif role == 'knowledge':\n",
    "            prompt += f\"<|im_start|>knowledge\\n{content}<|im_end|>\\n\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown role: {role}\")\n",
    "    \n",
    "    # 添加 assistant 的开始标记，表示模型需要生成回复\n",
    "    prompt += \"<|im_start|>assistant\\n\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b899f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:03,977 - INFO - Loading teacher model: /root/matrix/LLM-Models-Export/huzhiqiang/Qwen2-1.5B-Instruct_20250326-车辆匹配OK\n"
     ]
    }
   ],
   "source": [
    "# 加载教师模型（DeepSeek-R1:1.5B）\n",
    "teacher_model_name = os.path.join(\"/root/matrix/LLM-Models-Export/huzhiqiang/\", \"Qwen2-1.5B-Instruct_20250326-车辆匹配OK\")\n",
    "logger.info(f\"Loading teacher model: {teacher_model_name}\")\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name,\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(teacher_model_name,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68db0130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:04,735 - INFO - Loading student model: /root/LLMmodels/qwen/Qwen2___5-1___5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# 加载学生模型（Qwen）\n",
    "student_model_name = os.path.join(\"/root/LLMmodels/qwen/\", \"Qwen2___5-1___5B-Instruct\")  # 确保模型名称正确\n",
    "logger.info(f\"Loading student model: {student_model_name}\")\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name,\n",
    "    local_files_only=True\n",
    ")\n",
    "student_model = AutoModelForCausalLM.from_pretrained(student_model_name,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6567cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<任务>\n",
      "在货运领域，货主发货后会有司机（也叫用户）前来咨询，你是货主（也叫老板）的助手，任务是帮货主回答司机问题，你的回复需结合多维度的信息\n",
      "* [货源信息]和[备注]是货主发货时填写的要求，你的回复在提到货主要求时必须遵守二者，当二者信息有冲突时，默认以[备注]为准\n",
      "* [历史对话]记录了过去你、货主和司机的对话，你的回复需要关注其中的有用信息。注意[历史对话]中你的回复是可能出错的，不要受到过去自己错误回复的影响\n",
      "* [当前问题]是当前轮司机的问题，你必须理解清楚当前司机的意图再回复\n",
      "* [回复指令]记录了货主对司机车辆各维度提供的回复指令，你的回复若涉及这些维度，就必须遵从对应的回复指令。当指令内部或与外部其他信息有冲突时，优先考虑[历史对话]中的货主回复，再考虑[备注]，其次是行业知识指令，最后才是其他维度的指令\n",
      "* [通用规则]是指导你回复的一些通用性规则，优先级最低，但最通用\n",
      "</任务>\n",
      "\n",
      "<通用规则>\n",
      "* [当前问题]涉及多个维度时，若其中一个维度需拒绝，只用这个维度拒绝就行\n",
      "* [当前问题]中不涉及需拒绝的维度时，知道的就答，不知道的就说不知道（>=2个维度不知道时，可以简洁地表达为“其他的不知道”），不能忽略不答；若结合指令存在[当前问题]没提的需拒绝的维度，则进行提醒\n",
      "</通用规则>\n",
      "\n",
      "<货源信息>\n",
      "货名：太阳能板；包装方式：托盘；托盘/吨包数量：None；装卸方式：None；单个重量：None；总重量：2.0-4.0吨；总体积：None；总高度：None；需要车辆数：1；是否跟车：None；当前时间：2025-02-16 08:07:15；装货时间：最早2025-02-16 06:00:00，最晚2025-02-16 12:00:00；卸货时间：None；装货地址：四川省成都市金堂县淮口街道金乐路东段1号；卸货地址：四川省雅安市天全县大洼头；装卸次数：一装一卸；是否禁区：None；全程高速：None；价格类型：有价；订金：100.0；订金状态：订金非司机原因可退；价格单位：按趟；出价金额：850.0元；是否油卡支付：None；油卡支付金额：None；支付方式：到付；回单付金额：None；回单邮费是否报销：None；进门费：None；发票类型：企业专票；园区规章制度：None；运输距离：239；随车装备：None；双驾：None；温控范围：None\n",
      "用车类型：整车；老板需要车型：平板,高栏；老板需要车长：4.2米；老板需要车宽：None；零担占用车长：None\n",
      "</货源信息>\n",
      "\n",
      "<备注>\n",
      "9.6米高栏，车厢一定干净，今天下午装，明天下午卸，会高出龙门架40公分左右，平台付款\n",
      "</备注>\n",
      "\n",
      "<历史对话>\n",
      "助手：吴师傅你好，太阳能板到车价格850元，能接吗？\n",
      "用户：能加点吗?\n",
      "助手：你说个能走的价格，咱们商量商量\n",
      "助手：多少钱能接啊？说个数我看下\n",
      "</历史对话>\n",
      "\n",
      "<当前问题>\n",
      "2.3宽能不能行\n",
      "</当前问题>\n",
      "\n",
      "<回复指令>\n",
      "车型：不对司机车型做判断，而是根据司机意图，选择性告知货主需要/拒绝的车型、要求的车辆特殊情况等信息。但若司机主动表达自己车型不合适，则进行拒绝\n",
      "车长：不对司机车长做判断，而是根据司机意图，选择性告知货主需要的车长、货物占用车长、货物体积/重量/尺寸、是否可配货等信息。但若司机主动表达自己车长不合适，则进行拒绝\n",
      "车宽：不对司机车宽做判断，而是根据司机意图，选择性告知货主需要的具体车宽、是否要宽体等信息。但若司机主动表达自己车宽不合适，则进行拒绝\n",
      "行业知识：平板没有立柱，立柱相关的货主需求不能单独修饰平板\n",
      "</回复指令><|im_end|>\n",
      "<|im_start|>assistant\n",
      "车宽要求老板没说，老板要的是9.6米的高栏，你看看呢。<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "\n",
    "train_messages = json.load(open('/root/sunhao11/guorui/HZQ/prompt_data/车辆匹配sft.json', 'r',encoding='UTF-8'))\n",
    "valid_messages = json.load(open('/root/sunhao11/guorui/HZQ/prompt_data/truck_check_sft_2.json', 'r',encoding='UTF-8'))\n",
    "train_text = []\n",
    "valid_text = []\n",
    "for msg in train_messages:\n",
    "    train_text.append(messages_to_prompt(msg).strip())\n",
    "\n",
    "for msg in valid_messages:\n",
    "    valid_text.append(messages_to_prompt(msg).strip())\n",
    "    \n",
    "\n",
    "# datasets_name = os.path.join(current_script_dir, \"../models/Dataset/wikitext-2-raw/\")  # 确保模型名称正确\n",
    "# data_files = {\n",
    "#     \"train\": datasets_name+\"wiki.train.raw\",\n",
    "#     \"test\": datasets_name+\"wiki.test.raw\"\n",
    "# }\n",
    "# logger.info(f\"Loading dataset from local files: {data_files}\")\n",
    "# dataset = load_dataset(\"text\", data_files=data_files)\n",
    "train_dataset = train_text\n",
    "eval_dataset = valid_text\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a479b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:05,450 - INFO - Preprocess_function\n",
      "2025-04-24 18:15:05,451 - INFO - Preprocessing train dataset\n",
      "2025-04-24 18:15:10,159 - INFO - Preprocessing eval dataset\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "logger.info(f\"Preprocess_function\")\n",
    "def preprocess_function(examples):\n",
    "    return teacher_tokenizer(examples, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "logger.info(\"Preprocessing train dataset\")\n",
    "train_dataset = list(map(preprocess_function, train_dataset))\n",
    "logger.info(\"Preprocessing eval dataset\")\n",
    "eval_dataset = list(map(preprocess_function, eval_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8575142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:10,413 - INFO - DataCollatorForLanguageModeling\n"
     ]
    }
   ],
   "source": [
    "# 数据收集器\n",
    "logger.info(\"DataCollatorForLanguageModeling\")\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=teacher_tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8981fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:10,443 - INFO - Creating trainer\n"
     ]
    }
   ],
   "source": [
    "# 定义训练参数\n",
    "logger.info(\"Creating trainer\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",            # 训练结果保存路径\n",
    "    eval_strategy=\"epoch\",             # 每个epoch结束时评估\n",
    "    learning_rate=5e-5,                # 学习率（默认5e-5是常见选择）\n",
    "    per_device_train_batch_size=2,     # 每个设备的训练batch size（GPU单卡）\n",
    "    per_device_eval_batch_size=2,      # 每个设备的评估batch size\n",
    "    num_train_epochs=3,                # 训练轮次（3轮可能较短，需根据任务调整）\n",
    "    weight_decay=0.01,                 # 权重衰减（L2正则化）\n",
    "    logging_dir=\"./logs\",              # 日志保存路径\n",
    "    logging_steps=100,                 # 每100步记录一次日志\n",
    "    fp16=False,                        # 是否启用混合精度训练（建议开启）\n",
    "    gradient_accumulation_steps=4,     # 梯度累积步数（等效batch_size=8）\n",
    "    report_to=\"tensorboard\",           # 使用TensorBoard记录训练过程\n",
    "    # distributed_data_parallel=True\n",
    "    # tensorboard_dir=\"./tensorboard\"  # 可选：指定TensorBoard日志目录\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f544f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:11,341 - INFO - Creating distillation config\n"
     ]
    }
   ],
   "source": [
    "# 定义蒸馏配置  weight:添加权重，\"loss\": \"mse\"\n",
    "logger.info(\"Creating distillation config\")\n",
    "distill_config = DistillationConfig(\n",
    "    temperature=2.0,  # 温度参数，控制软标签的平滑程度\n",
    "    hard_label_weight=0.5,  # 真实标签损失权重\n",
    "    kd_loss_type=\"ce\",      # 知识蒸馏损失类型（交叉熵）\n",
    "    intermediate_matches=[  # 中间层匹配配置\n",
    "        {\n",
    "            \"layer_T\": 6,    # 教师模型的第6层\n",
    "            \"layer_S\": 6,    # 学生模型的第6层\n",
    "            \"feature\": \"hidden\",  # 匹配隐藏层特征\n",
    "            \"weight\": 1.0,   # 中间层损失权重\n",
    "            \"loss\": \"mse\"    # 使用均方误差损失\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc3ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:11,377 - INFO - Creating training config\n"
     ]
    }
   ],
   "source": [
    "# 定义训练配置\n",
    "logger.info(\"Creating training config\")\n",
    "train_config = TrainingConfig(\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # 设备选择\n",
    "    log_dir=\"./logs\",                                     # 日志目录\n",
    "    output_dir=\"./outputs\"                                # 模型输出目录\n",
    "    # save_best_model=True,  # 是否保存最佳模型（注释状态）\n",
    "    # save_last_model=True,  # 是否保存最后模型（注释状态）\n",
    "    # save_model_every_epoch=True,  # 是否每轮保存模型（注释状态）\n",
    "    # tensorboard_dir=\"./tensorboard\"  # TensorBoard日志目录（注释状态）\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606cd93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:11,412 - INFO - Creating distiller\n"
     ]
    }
   ],
   "source": [
    "# 创建蒸馏器\n",
    "logger.info(\"Creating distiller\")\n",
    "distiller = GeneralDistiller(\n",
    "    train_config=train_config,        # 训练配置（包含设备、路径等）\n",
    "    distill_config=distill_config,    # 蒸馏配置（温度、损失权重等）\n",
    "    model_T=teacher_model,            # 教师模型\n",
    "    model_S=student_model,            # 学生模型\n",
    "    adaptor_T=None,                   # 教师模型适配器（未配置）\n",
    "    adaptor_S=None                    # 学生模型适配器（未配置）\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43b713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:15:11,445 - INFO - Starting training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 46:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>3.578058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>3.884399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>4.245460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 19:01:33,511 - INFO - Training finished\n"
     ]
    }
   ],
   "source": [
    "# 开始蒸馏\n",
    "with distiller:  # 使用蒸馏器上下文管理器，确保资源正确初始化和释放\n",
    "    logger.info(\"Starting training\")  # 记录训练开始日志\n",
    "\n",
    "    # 初始化Trainer，集成模型蒸馏配置\n",
    "    trainer = Trainer(\n",
    "        model=student_model,  # 学生模型（需要训练的小模型）\n",
    "        args=training_args,  # 训练参数（如学习率、批次大小、设备等）\n",
    "        train_dataset=train_dataset,  # 训练数据集（包含输入和标签）\n",
    "        eval_dataset=eval_dataset,  # 验证数据集（用于评估模型性能）\n",
    "        data_collator=data_collator,  # 数据批量处理函数（将单条数据组合成批次）\n",
    "        \n",
    "        # processing_class=teacher_tokenizer  # 注意：此处可能存在问题（见下方说明）\n",
    "        # 正确做法：适配器或数据处理逻辑应在蒸馏配置中处理\n",
    "    )\n",
    "\n",
    "    # 开始模型训练\n",
    "    trainer.train()  # 启动训练循环，包含前向传播、损失计算、反向传播等\n",
    "    trainer.save_model()\n",
    "\n",
    "    logger.info(\"Training finished\")  # 记录训练结束日志\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hzq",
   "language": "python",
   "name": "hzq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
